{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38550eb-8e06-4e45-9674-10896aba03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import makemore as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6294a20c-7305-4d02-865d-7264b2f16e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67cabf9-f8f8-44a1-a00f-11b08bc90e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece33106-63b9-4bc0-b8e2-bcd284a5d19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d910827-07ab-4e5d-94a5-41531c3ebea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A6000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae87349-e270-46be-b2ce-ea2ff9bfd2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#args\n",
    "seed = 101010\n",
    "work_dir = '/home/ubuntu/models' #run `mkdir models` first\n",
    "input_file = 'names.txt'\n",
    "\n",
    "#Model Args\n",
    "n_layer=4\n",
    "n_embd=64\n",
    "n_embd2=64\n",
    "n_head=64\n",
    "device='cuda:0'\n",
    "\n",
    "#Trainer Args\n",
    "learning_rate=3e-4\n",
    "weight_decay=1e-2\n",
    "batch_size = 10\n",
    "num_workers = 2\n",
    "max_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fbcbb8-5944-4033-9335-924dd86082c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# system inits\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "writer = mm.SummaryWriter(log_dir=work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31d34c8-810d-4525-a36c-5e19634d128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/makemore'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df636d68-cd53-4c23-972c-124bf03b13df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples in the dataset: 32033\n",
      "max word length: 15\n",
      "number of unique characters in the vocabulary: 26\n",
      "vocabulary:\n",
      "abcdefghijklmnopqrstuvwxyz\n",
      "split up the dataset into 31033 training examples and 1000 test examples\n",
      "dataset determined that: vocab_size=27, block_size=16\n"
     ]
    }
   ],
   "source": [
    "# init datasets\n",
    "train_dataset, test_dataset = mm.create_datasets(input_file)\n",
    "vocab_size = train_dataset.get_vocab_size()\n",
    "block_size = train_dataset.get_output_length()\n",
    "print(f\"dataset determined that: {vocab_size=}, {block_size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9e0baa-285b-421a-a641-0e55c6234f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "config = mm.ModelConfig(vocab_size=vocab_size, block_size=block_size,\n",
    "                   n_layer=n_layer, n_head=n_head,\n",
    "                   n_embd=n_embd, n_embd2=n_embd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b8cc43-2773-4448-b270-1c15ff3da5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.20M\n"
     ]
    }
   ],
   "source": [
    "model = mm.Transformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d649afc0-35d7-46f5-a976-d4bc280389c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model #params: 204544\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(f\"model #params: {sum(p.numel() for p in model.parameters())}\")\n",
    "# if args.resume or args.sample_only: # note: if we sample-only then we also assume we are resuming\n",
    "#     print(\"resuming from existing model in the workdir\")\n",
    "#     model.load_state_dict(torch.load(os.path.join(args.work_dir, 'model.pt')))\n",
    "# if args.sample_only:\n",
    "#     print_samples(num=50)\n",
    "#     sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324e5ac1-5d20-423e-b7f0-18ef148fe898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=learning_rate, \n",
    "    weight_decay=weight_decay,\n",
    "    betas=(0.9, 0.99), \n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0400b4e6-d84b-4209-a6af-37f8c7477bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataloader\n",
    "batch_loader = mm.InfiniteDataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    pin_memory=True, \n",
    "    num_workers=num_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25551a62-9c09-4b75-ad82-6d6df40896bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss 3.4336 | step time 803.14ms\n",
      "step 10 | loss 3.0155 | step time 19.60ms\n",
      "step 20 | loss 2.9193 | step time 18.95ms\n",
      "step 30 | loss 2.6380 | step time 18.81ms\n",
      "step 40 | loss 2.6422 | step time 18.07ms\n",
      "step 50 | loss 2.6594 | step time 16.11ms\n",
      "step 60 | loss 2.7239 | step time 22.88ms\n",
      "step 70 | loss 2.6593 | step time 20.81ms\n",
      "step 80 | loss 2.5451 | step time 20.72ms\n",
      "step 90 | loss 2.4382 | step time 20.60ms\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "best_loss = None\n",
    "step = 0\n",
    "while True:\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # get the next batch, ship to device, and unpack it to input and target\n",
    "    batch = batch_loader.next()\n",
    "    batch = [t.to(device) for t in batch]\n",
    "    X, Y = batch\n",
    "\n",
    "    # feed into the model\n",
    "    logits, loss = model(X, Y)\n",
    "\n",
    "    # calculate the gradient, update the weights\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # wait for all CUDA work on the GPU to finish then calculate iteration time taken\n",
    "    if device.startswith('cuda'):\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "\n",
    "    # logging\n",
    "    if step % 10 == 0:\n",
    "        print(f\"step {step} | loss {loss.item():.4f} | step time {(t1-t0)*1000:.2f}ms\")\n",
    "\n",
    "    # evaluate the model\n",
    "    if step > 0 and step % 500 == 0:\n",
    "        train_loss = evaluate(model, train_dataset, batch_size=100, max_batches=10)\n",
    "        test_loss  = evaluate(model, test_dataset,  batch_size=100, max_batches=10)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, step)\n",
    "        writer.add_scalar(\"Loss/test\", test_loss, step)\n",
    "        writer.flush()\n",
    "        print(f\"step {step} train loss: {train_loss} test loss: {test_loss}\")\n",
    "        # save the model to disk if it has improved\n",
    "        if best_loss is None or test_loss < best_loss:\n",
    "            out_path = os.path.join(work_dir, \"model.pt\")\n",
    "            print(f\"test loss {test_loss} is the best so far, saving model to {out_path}\")\n",
    "            torch.save(model.state_dict(), out_path)\n",
    "            best_loss = test_loss\n",
    "\n",
    "    # sample from the model\n",
    "    if step > 0 and step % 200 == 0:\n",
    "        print_samples(num=10)\n",
    "\n",
    "    step += 1\n",
    "    # termination conditions\n",
    "    if max_steps >= 0 and step >= max_steps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcddf5-3e07-44f1-82fe-740ec6e6d891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2263a39-dc42-446d-af4e-a1176749b5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4fc1d-2e3f-48d0-bdc8-ed2cb77e6d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834483f-d71d-40a5-bc1d-0397ccf17179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a0ba0-6422-4184-8de5-e25f6e1a2b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4efb43-d8f8-4173-a082-d6146f37b476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cae5ed-4279-457f-9d67-369b0399688b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6473d5a-7910-458a-8d1d-5aa7f3afe796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c61d6-c8e5-47e2-a6d0-8fdd33b0be8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526eb4fc-9909-437e-acb6-c1ed7ad9d6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47983d85-d3be-4040-aa7c-d263681c68d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
